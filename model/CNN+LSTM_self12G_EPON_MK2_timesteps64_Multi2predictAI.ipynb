{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f740627c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cec5317a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gi\n",
       "0  22354\n",
       "1   3923\n",
       "2  38409\n",
       "3   6561\n",
       "4   9925"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('./SelfData_thesis/0630_self12GData_3to7_ONU16.csv', usecols=[1], engine='python')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18534f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ai\n",
       "0  22354\n",
       "1   3567\n",
       "2  35274\n",
       "3   9100\n",
       "4   8801"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('./SelfData_thesis/0630_self12GData_3to7_ONU16.csv', usecols=[2], engine='python')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a3fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3 = pd.read_csv('./SelfData_thesis/0628_self8GData_3to7_ONU16_limitData.csv', usecols=[2], engine='python')\n",
    "#df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bb7dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.values\n",
    "df1 = df1.astype('float32')\n",
    "\n",
    "df2 = df2.values\n",
    "df2 = df2.astype('float32')\n",
    "\n",
    "#df3 = df3.values\n",
    "#df3 = df3.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3a20fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195000.0\n",
      "568516.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(df1))\n",
    "print(np.max(df2))\n",
    "#print(np.max(df3))\n",
    "\n",
    "df1Max = np.max(df1)\n",
    "df2Max = np.max(df2)\n",
    "#df3Max = np.max(df3)\n",
    "\n",
    "df1 = df1 / np.max(df1) #手動正規化\n",
    "df2 = df2 / np.max(df2) #手動正規化\n",
    "#df3 = df3 / np.max(df3) #手動正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a66df84a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10162\n",
      "10162\n"
     ]
    }
   ],
   "source": [
    "print(len(df1))\n",
    "print(len(df2))\n",
    "#print(len(df3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "181b34e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetR = df1\n",
    "datasetA = df2\n",
    "#datasetT = df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5cf5570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8129 2033\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "train_sizeR = int(len(datasetR) * 0.8) \n",
    "test_sizeR = len(datasetR) - train_sizeR\n",
    "trainR, testR = datasetR[0:train_sizeR], datasetR[train_sizeR:len(datasetR)]\n",
    "\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#trainR = scaler.fit_transform(trainR)\n",
    "#testR = scaler.fit_transform(testR)\n",
    "print(len(trainR), len(testR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6facbe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8129 2033\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "train_sizeA = int(len(datasetA) * 0.8) \n",
    "test_sizeA = len(datasetA) - train_sizeA\n",
    "trainA, testA = datasetA[0:train_sizeA], datasetA[train_sizeA:len(datasetA)]\n",
    "\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#trainR = scaler.fit_transform(trainR)\n",
    "#testR = scaler.fit_transform(testR)\n",
    "print(len(trainA), len(testA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdd7d350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "#train_sizeT = int(len(datasetT) * 0.8) \n",
    "#test_sizeT = len(datasetT) - train_sizeT\n",
    "#trainT, testT = datasetT[0:train_sizeT], datasetT[train_sizeT:len(datasetT)]\n",
    "\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#trainR = scaler.fit_transform(trainR)\n",
    "#testR = scaler.fit_transform(testR)\n",
    "#print(len(trainT), len(testT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c7ee253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back - 1):\n",
    "        a = dataset[i:(i + look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "220edca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "look_back = 64 #16\n",
    "trainX_R, trainY_R = create_dataset(trainR, look_back)\n",
    "testX_R, testY_R = create_dataset(testR, look_back)\n",
    "\n",
    "trainX_A, trainY_A = create_dataset(trainA, look_back)\n",
    "testX_A, testY_A = create_dataset(testA, look_back)\n",
    "\n",
    "#trainX_T, trainY_T = create_dataset(trainT, look_back)\n",
    "#testX_T, testY_T = create_dataset(testT, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea08526c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8064, 64, 1)\n",
      "(8064, 1)\n",
      "(1968, 64, 1)\n",
      "(1968, 1)\n",
      "(8064, 64, 1)\n",
      "(8064, 1)\n",
      "(1968, 64, 1)\n",
      "(1968, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX_R = np.reshape(trainX_R, (trainX_R.shape[0], look_back, 1))\n",
    "testX_R = np.reshape(testX_R, (testX_R.shape[0], look_back, 1))\n",
    "\n",
    "trainX_A = np.reshape(trainX_A, (trainX_A.shape[0], look_back, 1))\n",
    "testX_A = np.reshape(testX_A, (testX_A.shape[0], look_back, 1))\n",
    "\n",
    "#trainX_T = np.reshape(trainX_T, (trainX_T.shape[0], look_back, 1))\n",
    "#testX_T = np.reshape(testX_T, (testX_T.shape[0], look_back, 1))\n",
    "#print(trainX.shape[1])\n",
    "\n",
    "print(trainX_R.shape)\n",
    "print(trainY_R.shape)\n",
    "print(testX_R.shape)\n",
    "print(testY_R.shape)\n",
    "\n",
    "print(trainX_A.shape)\n",
    "print(trainY_A.shape)\n",
    "print(testX_A.shape)\n",
    "print(testY_A.shape)\n",
    "\n",
    "#print(trainX_T.shape)\n",
    "#print(trainY_T.shape)\n",
    "#print(testX_T.shape)\n",
    "#print(testY_T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f8917fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import math\n",
    "#importing keras modules\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Activation ,Dropout , Flatten , Conv1D , MaxPooling1D\n",
    "from tensorflow.keras.layers import Input, Reshape, concatenate, LSTM\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d2cca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_R = Input(shape=(look_back,))\n",
    "inputs_A = Input(shape=(look_back,))\n",
    "#inputs_T = Input(shape=(look_back,))\n",
    "\n",
    "inputs_R_test = Reshape((inputs_R.shape[1], 1))(inputs_R)\n",
    "inputs_A_test = Reshape((inputs_A.shape[1], 1))(inputs_A)\n",
    "#inputs_T_test = Reshape((inputs_R.shape[1], 1))(inputs_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "046a6cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_list = []\n",
    "\n",
    "Ri_1 = Conv1D(filters=32,kernel_size=1,padding='same',activation='relu',kernel_initializer=\"glorot_uniform\")(inputs_R_test)\n",
    "Ri_2 = MaxPooling1D(pool_size=2,padding='valid')(Ri_1)\n",
    "Ri_3 = Conv1D(filters=32,kernel_size=1,padding='same',activation='relu',kernel_initializer=\"glorot_uniform\")(Ri_2)\n",
    "Ri_4 = MaxPooling1D(pool_size=2,padding='valid')(Ri_3)\n",
    "\n",
    "Ai_1 = Conv1D(filters=32,kernel_size=1,padding='same',activation='relu',kernel_initializer=\"glorot_uniform\")(inputs_A_test)\n",
    "Ai_2 = MaxPooling1D(pool_size=2,padding='valid')(Ai_1)\n",
    "Ai_3 = Conv1D(filters=32,kernel_size=1,padding='same',activation='relu',kernel_initializer=\"glorot_uniform\")(Ai_2)\n",
    "Ai_4 = MaxPooling1D(pool_size=2,padding='valid')(Ai_3)\n",
    "\n",
    "#Ti_1 = Conv1D(filters=32,kernel_size=1,padding='same',activation='relu',kernel_initializer=\"glorot_uniform\")(inputs_T_test)\n",
    "#Ti_2 = MaxPooling1D(pool_size=2,padding='valid')(Ti_1)\n",
    "#Ti_3 = Conv1D(filters=32,kernel_size=1,padding='same',activation='relu',kernel_initializer=\"glorot_uniform\")(Ti_2)\n",
    "#Ti_4 = MaxPooling1D(pool_size=2,padding='valid')(Ti_3)\n",
    "\n",
    "Ri_5 = Flatten()(Ri_4)\n",
    "head_list.append(Ri_5)\n",
    "Ai_5 = Flatten()(Ai_4)\n",
    "head_list.append(Ai_5)\n",
    "#Ti_5 = Flatten()(Ti_4)\n",
    "\n",
    "out = concatenate(head_list, axis = 1)\n",
    "reshape = Reshape((head_list[0].shape[1], 2))(out)\n",
    "#out = concatenate([Ri_5, Ai_5, Ti_5], axis = -1)\n",
    "tgt6 = LSTM(32,return_sequences=True)(reshape)\n",
    "tgt7 = LSTM(32,return_sequences=False)(tgt6)\n",
    "\n",
    "predictions = Dense(1, activation=\"relu\", kernel_initializer=\"uniform\")(tgt7)\n",
    "\n",
    "model = Model([inputs_R, inputs_A], outputs = predictions)\n",
    "model.compile(loss='mae',optimizer='Adam',metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcba5ad0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 64, 1)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 64, 1)        0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 64, 32)       64          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 64, 32)       64          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 32, 32)       0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 32, 32)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 32, 32)       1056        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 32, 32)       1056        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 16, 32)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 16, 32)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 512, 2)       0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 512, 32)      4480        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           8320        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 15,073\n",
      "Trainable params: 15,073\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df1cecf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "101/101 - 4s - loss: 0.0256 - mse: 0.0024 - mae: 0.0256 - val_loss: 0.0205 - val_mse: 0.0010 - val_mae: 0.0205\n",
      "Epoch 2/30\n",
      "101/101 - 3s - loss: 0.0236 - mse: 0.0024 - mae: 0.0236 - val_loss: 0.0179 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 3/30\n",
      "101/101 - 3s - loss: 0.0225 - mse: 0.0023 - mae: 0.0225 - val_loss: 0.0178 - val_mse: 9.7085e-04 - val_mae: 0.0178\n",
      "Epoch 4/30\n",
      "101/101 - 3s - loss: 0.0222 - mse: 0.0023 - mae: 0.0222 - val_loss: 0.0170 - val_mse: 9.9454e-04 - val_mae: 0.0170\n",
      "Epoch 5/30\n",
      "101/101 - 3s - loss: 0.0221 - mse: 0.0023 - mae: 0.0221 - val_loss: 0.0172 - val_mse: 9.6445e-04 - val_mae: 0.0172\n",
      "Epoch 6/30\n",
      "101/101 - 3s - loss: 0.0221 - mse: 0.0023 - mae: 0.0221 - val_loss: 0.0172 - val_mse: 0.0010 - val_mae: 0.0172\n",
      "Epoch 7/30\n",
      "101/101 - 3s - loss: 0.0220 - mse: 0.0023 - mae: 0.0220 - val_loss: 0.0171 - val_mse: 9.8263e-04 - val_mae: 0.0171\n",
      "Epoch 8/30\n",
      "101/101 - 3s - loss: 0.0220 - mse: 0.0023 - mae: 0.0220 - val_loss: 0.0169 - val_mse: 9.9247e-04 - val_mae: 0.0169\n",
      "Epoch 9/30\n",
      "101/101 - 3s - loss: 0.0219 - mse: 0.0023 - mae: 0.0219 - val_loss: 0.0171 - val_mse: 9.6692e-04 - val_mae: 0.0171\n",
      "Epoch 10/30\n",
      "101/101 - 3s - loss: 0.0219 - mse: 0.0023 - mae: 0.0219 - val_loss: 0.0170 - val_mse: 9.7917e-04 - val_mae: 0.0170\n",
      "Epoch 11/30\n",
      "101/101 - 3s - loss: 0.0219 - mse: 0.0023 - mae: 0.0219 - val_loss: 0.0170 - val_mse: 9.7238e-04 - val_mae: 0.0170\n",
      "Epoch 12/30\n",
      "101/101 - 3s - loss: 0.0221 - mse: 0.0023 - mae: 0.0221 - val_loss: 0.0170 - val_mse: 9.8476e-04 - val_mae: 0.0170\n",
      "Epoch 13/30\n",
      "101/101 - 3s - loss: 0.0219 - mse: 0.0023 - mae: 0.0219 - val_loss: 0.0171 - val_mse: 9.8920e-04 - val_mae: 0.0171\n",
      "Epoch 14/30\n",
      "101/101 - 3s - loss: 0.0225 - mse: 0.0023 - mae: 0.0225 - val_loss: 0.0170 - val_mse: 9.7516e-04 - val_mae: 0.0170\n",
      "Epoch 15/30\n",
      "101/101 - 3s - loss: 0.0219 - mse: 0.0023 - mae: 0.0219 - val_loss: 0.0170 - val_mse: 9.6973e-04 - val_mae: 0.0170\n",
      "Epoch 16/30\n",
      "101/101 - 3s - loss: 0.0219 - mse: 0.0023 - mae: 0.0219 - val_loss: 0.0170 - val_mse: 0.0010 - val_mae: 0.0170\n",
      "Epoch 17/30\n",
      "101/101 - 3s - loss: 0.0219 - mse: 0.0023 - mae: 0.0219 - val_loss: 0.0169 - val_mse: 9.8569e-04 - val_mae: 0.0169\n",
      "Epoch 18/30\n",
      "101/101 - 3s - loss: 0.0219 - mse: 0.0023 - mae: 0.0219 - val_loss: 0.0169 - val_mse: 0.0010 - val_mae: 0.0169\n",
      "Epoch 19/30\n",
      "101/101 - 3s - loss: 0.0219 - mse: 0.0023 - mae: 0.0219 - val_loss: 0.0169 - val_mse: 0.0010 - val_mae: 0.0169\n",
      "Epoch 20/30\n",
      "101/101 - 4s - loss: 0.0219 - mse: 0.0023 - mae: 0.0219 - val_loss: 0.0170 - val_mse: 9.6921e-04 - val_mae: 0.0170\n",
      "Epoch 21/30\n",
      "101/101 - 4s - loss: 0.0272 - mse: 0.0029 - mae: 0.0272 - val_loss: 0.0248 - val_mse: 0.0018 - val_mae: 0.0248\n",
      "Epoch 22/30\n",
      "101/101 - 4s - loss: 0.0318 - mse: 0.0034 - mae: 0.0318 - val_loss: 0.0248 - val_mse: 0.0018 - val_mae: 0.0248\n",
      "Epoch 23/30\n",
      "101/101 - 4s - loss: 0.0318 - mse: 0.0034 - mae: 0.0318 - val_loss: 0.0248 - val_mse: 0.0018 - val_mae: 0.0248\n",
      "Epoch 24/30\n",
      "101/101 - 4s - loss: 0.0318 - mse: 0.0034 - mae: 0.0318 - val_loss: 0.0248 - val_mse: 0.0018 - val_mae: 0.0248\n",
      "Epoch 25/30\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "start = timer()\n",
    "history = model.fit([trainX_R, trainX_A],\n",
    "                    trainY_A,\n",
    "                    batch_size=64,\n",
    "                    epochs=30,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=2)\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a691dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0fcff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('timesteps : ', look_back)\n",
    "plt.plot(history.history['mae'])\n",
    "plt.title('mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297cb9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('timesteps : ', look_back)\n",
    "plt.plot(history.history['mse'])\n",
    "plt.title('mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c42651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('loss')\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d929721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画出训练集和验证集的损失曲线\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "loss_values50 = loss_values[0:150]\n",
    "val_loss_values50 = val_loss_values[0:150]\n",
    "epochs = range(1, len(loss_values50) + 1)\n",
    "plt.plot(epochs, loss_values50, 'b',color = 'blue', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values50, 'b',color='orange', label='Validation loss')\n",
    "plt.rc('font', size = 18)\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.xticks(epochs)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15,7)\n",
    "#fig.savefig('img/tcstest&validationlosscnn.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9657540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画出训练集和验证集的误差图像\n",
    "\n",
    "#mae = history_dict['mean_absolute_error']\n",
    "#vmae = history_dict['val_mean_absolute_error']\n",
    "mae = history.history['mae']\n",
    "vmae = history.history['val_mae']\n",
    "epochs = range(1, len(mae) + 1)\n",
    "plt.plot(epochs, mae, 'b',color = 'blue', label='Training error')\n",
    "plt.plot(epochs, vmae, 'b',color='orange', label='Validation error')\n",
    "plt.title('Training and validation error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.xticks(epochs)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15,7)\n",
    "#fig.savefig('img/tcstest&validationerrorcnn.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c3da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names\n",
    "\n",
    "trainScore = model.evaluate([trainX_R, trainX_A], trainY_A, verbose=0)\n",
    "testScore = model.evaluate([testX_R, testX_A], testY_A, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceab892",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predicting values for y_test\n",
    "p = model.predict([testX_R, testX_A])\n",
    "\n",
    "plt.plot(testY_A, label='y_test')\n",
    "plt.plot(p, label='prediction')\n",
    "plt.xlabel('test data Ai')\n",
    "plt.ylabel('predict Ai')\n",
    "plt.legend(loc='upper left')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 5)\n",
    "#fig.savefig('img/tcstestcnn.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2308503",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "p1 = model.predict([trainX_R, trainX_A])\n",
    "\n",
    "plt.plot(trainY_A, label='y_train')\n",
    "x = np.array(range(8524,10655)) #range(x_train shape第一個數字的0.8倍, x_train shape第一個數字)\n",
    "plt.plot(x,p1[8524:],color = 'magenta',label ='prediction on validating samples') #p1[數字:] 數字代表x_train shape第一個數字的0.8倍\n",
    "plt.plot(p1[:8524],color='red', label='prediction on training samples')\n",
    "#x = np.array(range(29512,36890)) #range(x_train shape第一個數字的0.8倍, x_train shape第一個數字)\n",
    "#plt.plot(x,p1[29512:],color = 'magenta',label ='prediction on validating samples')\n",
    "#plt.plot(y_train,color='blue', label='y_train')\n",
    "plt.xlabel('No. of Trading Days')\n",
    "plt.ylabel('Close Value (scaled)')\n",
    "plt.legend(loc='upper left')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(20,10)\n",
    "#fig.savefig('img/tcstraincnn.png', dpi=300)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0c1058",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#手動正規化\n",
    "y = testY_A * df2Max   \n",
    "y_pred = p.reshape(2615)  \n",
    "y_pred = y_pred * df2Max   \n",
    "\n",
    "Ytrain = trainY_A * df2Max\n",
    "Ytest = testY_A * df2Max\n",
    "\n",
    "PP = p * df2Max\n",
    "P1 = p1 * df2Max\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e65e398",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print('Trainscore RMSE \\tTrain Mean abs Error \\tTestscore Rmse \\t Test Mean abs Error')\n",
    "print('%.9f \\t\\t %.9f \\t\\t %.9f \\t\\t %.9f' % (math.sqrt(trainScore[0]),trainScore[1],math.sqrt(testScore[0]),testScore[1]))\n",
    "\n",
    "print('mean absolute error \\t mean absolute percentage error')\n",
    "print(' %.9f \\t\\t\\t %.9f' % (mean_absolute_error(y,y_pred),(np.mean(np.abs((y - y_pred) / y)) * 100)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9addaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print('mean squared error = ')\n",
    "print(tf.keras.losses.mean_squared_error(y, y_pred))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Y = np.concatenate((Ytrain,Ytest),axis = 0)\n",
    "plt.plot(Y, label='Y')\n",
    "P = np.concatenate((P1,PP),axis = 0)\n",
    "#plotting the complete Y set with predicted values on x_train and x_test(variable p1 & p respectively given above)\n",
    "#for \n",
    "plt.plot(P[:8524],color='red', label='prediction on training samples') #p[:數字] 數字代表x_train shape第一個數字的0.8倍\n",
    "#for validating samples\n",
    "z = np.array(range(8524,10655)) #range(x_train shape第一個數字的0.8倍, x_train shape第一個數字)\n",
    "plt.plot(z,P[8524:10655],color = 'orange',label ='prediction on validating samples') #P[x_train shape第一個數字的0.8倍:x_train shape第一個數字]\n",
    "#for testing samples\n",
    "x = np.array(range(10655,13270)) #range(x_train shape第一個數字, x_train shape第一個數字 + x_test shape第一個數字)\n",
    "plt.plot(x,P[10655:],color = 'purple',label ='prediction on testing samples(x_test)') #p[數字:] 數字代表x_train shape第一個數字\n",
    "\n",
    "#plt.plot(Y,color='blue', label='Y')\n",
    "plt.legend(loc='upper left')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(20,12)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4441319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "plt.plot(Ytest[:300], label='y_test')\n",
    "plt.plot(PP[:300], label='prediction')\n",
    "plt.title('ONU16 request')\n",
    "plt.xlabel('Test Case')\n",
    "plt.ylabel('Ai')\n",
    "plt.legend(loc='upper left')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 10)\n",
    "#fig.savefig('img/tcstestcnn.png', dpi=300)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9a73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model, to_file='CNNLSTMmodel_GiAipredictAi.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4aa08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('./SelfData_thesis/0715_U12D00_CNNLSTM_ONU16_Gi195000_Ai568516_Ai_4layer_timesteps64_epoch30.h5', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11048d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
