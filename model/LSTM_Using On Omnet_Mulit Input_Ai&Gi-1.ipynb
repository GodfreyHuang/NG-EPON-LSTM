{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "242e0258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1427b17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[906.0, 472.0, 906.0, 472.0, 906.0, 472.0, 906.0, 472.0, 906.0, 472.0]\n"
     ]
    }
   ],
   "source": [
    "text_file = open(\"AIerror_ONU16_15S_Ai.txt\",\"r\")#ONU_16_GrantDownLoadSizePerCycle, ONU[27]_GrantDown.txt\n",
    "lines = text_file.readlines()\n",
    "i = 0\n",
    "\n",
    "ONU16_15S_Ai = []\n",
    "\n",
    "for line in lines:\n",
    "    if i < 1000:\n",
    "        n = float(line)\n",
    "        if n >= 0:\n",
    "            ONU16_15S_Ai.append(float(line))\n",
    "    i = i + 1\n",
    "    \n",
    "print(len(ONU16_15S_Ai))\n",
    "print(ONU16_15S_Ai[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b6bf0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_size :  1000\n",
      "train_size :  700\n",
      "test_size :  300\n"
     ]
    }
   ],
   "source": [
    "ONU16_15S_Ai = np.array(ONU16_15S_Ai)\n",
    "dataA = []\n",
    "data_size = len(ONU16_15S_Ai)    \n",
    "train_size = data_size - 300 \n",
    "test_size = 300             \n",
    "timesteps_ = 10              \n",
    "print('data_size : ',data_size)\n",
    "print('train_size : ',train_size)\n",
    "print('test_size : ',test_size)\n",
    "\n",
    "for info in ONU16_15S_Ai:      \n",
    "    dataA.append(info) \n",
    "\n",
    "dataA = np.array(dataA) \n",
    "dataA = np.reshape(dataA,(data_size, 1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00096f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet, TestSet = np.zeros(train_size), np.zeros(test_size) #\n",
    "TrainSet, TestSet = dataA[0:len(TrainSet)], dataA[len(TrainSet):dataA.shape[0]]#\n",
    "TrainSet, TestSet = np.array(TrainSet), np.array(TestSet)\n",
    "TrainSet, TestSet = np.reshape(TrainSet,(len(TrainSet),1)), np.reshape(TestSet,(len(TestSet),1))\n",
    "\n",
    "X_train_A = []\n",
    "Y_train_A = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8509d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "TrainSet = sc.fit_transform(TrainSet)\n",
    "\n",
    "period = timesteps_\n",
    "end_of_TrainSet = train_size\n",
    "\n",
    "print('type(TrainSet) : ',type(TrainSet))\n",
    "print('TrainSet.shape : ',TrainSet.shape)\n",
    "\n",
    "for i in range(period,end_of_TrainSet): #\n",
    "    X_train_A.append(TrainSet[i-period:i,0])\n",
    "    Y_train_A.append(TrainSet[i,0])\n",
    "\n",
    "print('type(X_train) : ',type(X_train))\n",
    "print('type(Y_train) : ',type(Y_train))    \n",
    "    \n",
    "X_train_A, Y_train_A = np.array(X_train_A), np.array(Y_train_A)\n",
    "X_train_A = np.reshape(X_train_A,(X_train_A.shape[0], X_train.shape_A[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f6914d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b803be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputsR = Input(shape=(timesteps,))\n",
    "inputsA = Input(shape=(timesteps,))\n",
    "inputsG = Input(shape=(timesteps,))\n",
    "#inputs = LayerNormalization(axis=1)(inputs)\n",
    "#inputs_R_test = Reshape((inputs_R.shape[1],1))(inputs_R)\n",
    "inputs_A_test = Reshape((inputs_A.shape[1],1))(inputs_A)\n",
    "inputs_G_test = Reshape((inputs_G.shape[1],1))(inputs_G)\n",
    "input_merge = concatenate([inputs_A_test,inputs_Gtest], axis = 1)\n",
    "tgt1 = Reshape((timesteps,2))(input_merge)\n",
    "\n",
    "\n",
    "tgt1 = LSTM(units=40, return_sequences = True, inputshape=(timesteps,2))(tgt1)\n",
    "tgt1 = Dropout(0.2)(tgt1)\n",
    "\n",
    "tgt2 = LSTM(units=40,return_sequences = True)(tgt1)\n",
    "tgt2 = Dropout(0.2)(tgt2)\n",
    "\n",
    "tgt3 = LSTM(units=40,return_sequences = True)(tgt2)\n",
    "tgt3 = Dropout(0.2)(tgt3)\n",
    "\n",
    "tgt4 = LSTM(units=40)(tgt3)\n",
    "tgt4 = Dropout(0.2)(tgt4)\n",
    "\n",
    "#tgt5 = Flatten()(tgt4)\n",
    "predictions = Dense(1, activation='relu')(tgt4)\n",
    "\n",
    "\n",
    "model = Model(inputs=[inputs_A, inputs_G], outputs=predictions)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mse','mae'])\n",
    "\n",
    "history = model.fit([X_train_A, X_train_G], Y_train_A, epochs=100, batch_size=32) #[1,0,0], [0,0,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
